{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4214d50-c08a-455b-9397-c14903b1825d",
   "metadata": {},
   "source": [
    "<img src=\"./images/adam-header.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e84c8-6d98-42e3-9616-5623b642f4f9",
   "metadata": {},
   "source": [
    "**IT IS FREAKIN' SIMPLE AS FUCK**:\n",
    "- Here, we just calculate RMSProp and Momentum\n",
    "- Just like we did them in their individual ways. Nothing crazy.\n",
    "- Calculate the storages using EWMA and done.\n",
    "- The **change** is only in the \"update\" formulae.\n",
    "\n",
    "Let's see that down below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e1092-a65d-4c25-b369-5c599e5d6ea7",
   "metadata": {},
   "source": [
    "**COMPUTE GRADIENTS**:\n",
    "- $dW_t, \\; db_t$\n",
    "\n",
    "**FIRST MOMENT ESTIMATE (momentum)**:\n",
    "- $v_{dW} = \\beta_1 v_{dW} + (1 - \\beta_1) dW_t$\n",
    "- $v_{db} = \\beta_1 v_{db} + (1 - \\beta_1) db_t$\n",
    "\n",
    "**SECOND MOMENT ESTIMATE (RMSprop)**:\n",
    "- $S_{dW} = \\beta_2 S_{dW} + (1 - \\beta_2) (dW_t)^2$\n",
    "- $S_{db} = \\beta_2 S_{db} + (1 - \\beta_2) (db_t)^2$\n",
    "\n",
    "**BIAS CORRECTION (yes, advised here!)**:\n",
    "- $\\hat{v}_{dW} = \\frac{v_{dW}}{1 - \\beta_1^t}, \\;\\;\\; \\hat{S}_{dW} = \\frac{s_{dW}}{1 - \\beta_2^t}$\n",
    "- $\\hat{v}_{db} = \\frac{v_{db}}{1 - \\beta_1^t}, \\;\\;\\; \\hat{S}_{db} = \\frac{s_{db}}{1 - \\beta_2^t}$\n",
    "\n",
    "**PARAMETER UPDATES**:\n",
    "- $W = W - \\alpha \\frac{\\hat{v}_{dW}}{\\sqrt{\\hat{S}_{dW}}}$\n",
    "- $b = b - \\alpha \\frac{\\hat{v}_{db}}{\\sqrt{\\hat{S}_{db}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d47a9-3799-422a-bb61-ae4f455c2150",
   "metadata": {},
   "source": [
    "## Visually...\n",
    "\n",
    "<img src=\"./images/adam-parts.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afda383-d494-4f5d-9e32-b59a738ef963",
   "metadata": {},
   "source": [
    "#### üí¨ What Andrew is saying ‚Äî in bro-speak:\n",
    "- \"**Bro, there‚Äôs a LOT of hype around new optimizers every year. But most of them are just fancy wrappers over good old gradient descent.**\"\n",
    "\n",
    "People keep inventing <u>new bullshit</u> trying to outperform basic GD + momentum, but most of it is like:\n",
    "- ‚Äú**Yo look! I made a new optimizer, it‚Äôs called DragonFireLROptimX‚Ñ¢ üòé‚Äù ...and then it crashes and burns in real tasks.**\n",
    "\t\n",
    "#### üí£ But RMSProp & Adam?\n",
    "They actually changed the fucking game.\n",
    "\n",
    "- **\"Out of the few that actually mattered, RMSProp and Adam delivered consistently across architectures. They‚Äôre not just hype.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e597f-cb42-48d7-aa7d-bbbd2f38bd7d",
   "metadata": {},
   "source": [
    "<img src=\"./images/ewma-tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e052b61-eff9-4011-a263-c4faf9545b32",
   "metadata": {},
   "source": [
    "<img src=\"./images/adam-fullform.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f1c35-219a-4896-b162-e3b6f77eb38c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
